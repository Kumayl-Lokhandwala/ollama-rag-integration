[[["0803c827-69a0-4130-8073-d98ce60473b6",{"pageContent":"2025 International Conference on Data Science, Agents, and Artificial Intelligence (ICDSAAI 2025) \n28-29 March 2025, Chennai, India \n \n979-8-3315-3755-5/25/$31.00 ©2025 IEEE \nDeveloping a User-Friendly Conversational AI \nAssistant for University Using Ollama and LLama3 \n \nJayrajsinh Gohil \nFaculty of Computer Applications \nMarwadi University \nRajkot, India \nhttps://orcid.org/0009000059132954 \n \nHagos L.Shifare \nDepartment of AI, ML and DS \nMarwadi University \nRajkot, India \nhttps://orcid.org/0009000314489425 \n \nMadhu Shukla \nDepartment of AI, ML and DS \nMarwadi University \nRajkot, India \nhttps://orcid.org/0000-0002-8023-7854 \n \nAbstract—This  paper  presents  the  development  and \nimplementation  of  an  AI-driven  chatbot  for  a  university, \ndesigned to assist students and parents by providing accurate \nand  instant  information  about  the  university.  The  chatbot \nleverages  advanced  LLM  technologies,  specifically  LLama3, \nintegrated with Ollama, to ensure high-quality natural language \nprocessing. Using LangChain, the system processes user queries \nby  combining  them  with  a  structured  prompt  template, \ngenerating  precise  responses,  and  storing  interactions  in  a \ndatabase  for  future  reference.  The  architecture  includes \nmodules like login, signup, and chat, ensuring a user-friendly \ninterface.  The  chatbot's  capability  to  reliably  give  precise \nresponses was evaluated both manually and with volunteers in \nactual  situations.  This  project  showcases  the  uniqueness  of \nutilizing  Ollama  and  LLama3,  which  distinguishes  it  from \nconventional solutions by providing incredibly trustworthy and \nrelevant replies. The chatbot enhances the user experience and \nacts  as  an  efficient  virtual  assistant  for  the  university  by \nbridging  the  gap  between  user  inquiries  and  institutional \nresources. \n \nKeywords—Chatbot,   Prompt   Engineering,   Ollama, \nUniversity Chatbot, Large Language Model. \n \n \nI.   INTRODUCTION \nIn the past, before computers existed, it was difficult for \npeople to find information about a particular topic. With the \ninvention of computers, accessing information became easier, \nallowing people to gather data from anywhere and at any time. \nHowever, even with computers, finding the right information \noften  required  visiting  multiple  web  pages  and  websites, \nwhich  was  time-consuming.  The  arrival  of  Artificial \nIntelligence (AI) changed this by making information easier \nto access and use. In a similar way, getting information about \na  company  or  university  often  means  searching  through \nseveral sources. \nThis paper presents a solution to that problem: a chatbot \ndesigned specifically for Universities. This chatbot gathers all \nthe important details about the university in one place, making \nit  easy  for  students  and  parents  to  find  information  about \nplacements, fees, facilities, and more. \nIn today's digital world, AI tools have become dominant, \nwith chatbots emerging as a key player due to their ability to \nprovide quick answers, efficiently resolve user queries, and \nfoster engaging interactions. This paper explores the creation \nand use of an AI chatbot for Marwadi University, which is \ndesigned to provide clear and accurate information to students, \nparents, and applicants. Despite the growing adoption of AI \nchatbots  in  higher  education,  there  remains  a  significant \nresearch gap in understanding their long-term impact on user \nengagement  and  satisfaction,  particularly  in  the  context  of \nIndian  universities.  This  study  aims  to  bridge  this  gap  by \ninvestigating the practical implications of implementing such \nsystems,  utilizing  state-of-the-art  technologies  like  Ollama \nand Llama 3. The proposed chatbot uses advanced Language \nLearning  Models  (LLMs)  and  tools  like  LangChain, \nsupported by a Django-based backend. With natural language \nprocessing (NLP), the chatbot can interact in a way that feels \nnatural  and  human-like,  ensuring  accurate  and  helpful \nresponses. The main goals are to make university information \neasy to access, reduce the workload on staff, and improve the \nexperience for users. This paper also discusses the methods, \ntechnology,  and  practical  uses  of  the  chatbot.  It  addresses \nchallenges  like  data  security,  scalability,  and  user interface \ndesign. By sharing these insights, this study contributes to the \ngrowing research on how AI can be used in education and \nprovides a model that other institutions can follow.  \nII.   LITERATURE REVIEW \nThe use of chatbots nowadays in universities is necessary \nbecause  it  makes  the  interaction  between  the  academic \nsupports and the administrative more easy and fast, and also it \nprovides  momenta  services  without  any  delays.  The  NEU \nchatbot was created by the authors in [1] with the intention of \nexpediting the National Economics University of Vietnam's \nadmissions procedures. with higher performance, which was \nshown by the advanced deep learning models in that field, \nwhich  achieved  more  than  97%  in  handling  the  questions \ncompared  to  Rasa  chatbots,  which  are  open-source  and \nprovide this type of app. \n To remain current, the system needed yearly updates by \nhand. In that paper [2], they did the same functionality using \na new version of chatbots based on the student behavior itself, \nand that step helped the deep model to understand and classify \nthe  types  of  questions,  and  that  made  the  process  of \nunderstanding the behavior of humans easier, and also it made \nthat model more trustworthy. For university-related questions, \nthe authors of another study in [3] presented EduChat, a hybrid \nAI  chatbot  that  combines  rule-based  systems,  machine \nlearning, and ChatGPT. Although it was limited in its ability \nto handle real-time updates, the chatbot's architecture allowed \nfor effective information retrieval. \n2025 International Conference on Data Science, Agents & Artificial Intelligence (ICDSAAI) | 979-8-3315-3755-5/25/$31.00 ©2025 IEEE | DOI: 10.1109/ICDSAAI65575.2025.11011878\nAuthorized licensed use limited to: VIT University. Downloaded on June 25,2025 at 10:47:02 UTC from IEEE Xplore.  Restrictions apply. \n\n2 \n \n In  research  conducted  by  [4],  the  authors  created an \nAnglo-Bangla chatbot specifically designed for universities in \nBangladesh,  overcoming  language  barriers  by  editing  the \nmodel  trained  on  both  Anglo-Bangla  and  English  datasets. \nhybrid model, which is combined deep learning with PLS-\nSEM to measure the importance of understanding the logic \nbetween the user of that chatbot and the types of questions \ndelieverd  by  them,  and  they  achieved  high  accuracy by \nmaking  this  combination  [5].  Their  results  of  that research \nhighlighted  the  main  role  of  trust,  interaction  quality,  and \nethical  design  in  shaping  user  acceptance  and  how  it  may \naffect the behavior of data.  \nIn the research [6], the author focused on analyzing the \nresults that come out of their studies to show how it may affect \nthe relation between humans and chatbots, the development of \nhuman-computer interaction was explored, showing how AI \nchatbots  enhance  user  experiences  by  providing  dynamic \nintelligence and streamlining university admissions.  \nAll of those studies tried to build robust trust between the \ncustomers and that AI and itself. Technologically, the research \nin  [7]  introduced  BARKPLUG  V.2,  which  used  Retrieval \nAccelerated  Generation  (RAG)  pipelines  for  managing \nuniversity resources. The chatbot demonstrated high accuracy \nand user satisfaction in domain-specific tasks. The authors of \nthat paper [8] applied a new deep learning model combined \nwith natural language processing (NLP) to create a bilingual \nchatbot, enabling effective communication in both Fijian and \nEnglish. Finally, the authors in [9] and [10] concentrated on \ncreating chatbots for significant determination and frequently \nasked questions, respectively.  \nWhile  previous  works  have  excelled  in  areas  like \nmultilingual   support,   FAQ   handling,   and   academic \nengagement,  challenges  persist  in  adaptability,  domain-\nspecific  accuracy,  and  user  interaction  modalities.  This \nproposed  research  has  integrated  fine-tuned  recent LLMs, \nsecure  user authentication,  and  voice-based communication \ninto  a  unified  framework.  By  addressing  scalability  and \ncontextual relevance, this approach sets a new benchmark for \nAI-driven educational tools tailored to the University's needs. \nIII. METHODOLOGY\n AND SYSTEM DESIGN \nThis  section  provides  an  in-depth  explanation  of  the \nworking system of the project, segmented into the following  \nmain  parts:  Data  Description  and  Preprocessing,  which \nexplains the data collection process and its transformation for \ntraining,  Ollama  and  LLama3  Implementation,  showcasing \nthe   workflow   and   implementation,   Testing   Model \nPerformance, evaluating the model’s output and effectiveness, \nFrontend  Design,  and  Backend  Development,  detailing  the \nbackend processes of the web portal. Each part highlights the \nmethodology, tools, and processes used to build the AI chatbot \nsystem   for   Marwadi   University,   ensuring   efficient \nperformance  and  user  accessibility.  Fig.  1  illustrates  the \noverall system architecture of the work. \nA. Dataset Description and Preprocessing \nThis  phase  focuses  on  collecting,  organizing,  and \npreparing the data required for the chatbot’s functionality. For \nthis  research  project,  we  manually  gathered  data  from  the \nofficial  Marwadi  University  website,  Google  searches,  and \nother  relevant  sources.  The  text  data  was  categorized  and \nstored  systematically  in  directories  and  text  files,  each \nrepresenting a specific category, as illustrated in Fig.  2. A \ntotal  of  19  text  files  were  created,  with  each  containing \napproximately 800-1000 lines of data. The dataset included \ninformation  about  various departments,  facilities, and other \naspects of the university. \nThe  manually  created  dataset  underwent  preprocessing, \nincluding  text-to-embedding  conversion  using  the  all-\nMiniLM-L6-v2  model,  to  optimize  compatibility  with the \nfine-tuned Llama3 model. To ensure real-time accuracy, the \ndataset is updated annually. \nB. Ollama and LLama3 Implementation \nThis  section  provides  a  detailed  overview  of  the \nintegration of Ollama and LLama3 in the project, highlighting \ntheir  role  in  processing  user  input  through  LangChain. \nAdditionally, it emphasizes the advantages and uniqueness of \nusing these technologies in comparison to older approaches. \nThe system begins by accepting user input, which is first \nsent to the LangChain framework. LangChain facilitates the \ncombination of the input with a predefined prompt template. \nThis structured prompt ensures that the input aligns with the \ncontext  and  format  required  by  the  language  model. Once \ncombined, the formatted input is processed by the core LLM, \nLLama3, with the help of Ollama. \nOllama  acts  as  a  lightweight  and  efficient  interface  for \ndeploying and interacting with LLama3. By utilizing Ollama, \nthe  research  work  achieves  enhanced  flexibility,  better \ndeployment efficiency, and optimized performance. LLama3, \nbeing  a  state-of-the-art  language  model,  generates highly \naccurate and context-aware responses based on the user input \nand  the  combined  prompt.  The  generated  response  is then \nreturned  to  the  user,  displayed  on  the  interface,  and \nsimultaneously stored in the database for future reference. \nThe architecture, depicted in Fig. 3, illustrates the flow of \ndata  from  user  input  to  the  final output. This  distinguishes \n \nFig.1. System Block Diagram \nAuthorized licensed use limited to: VIT University. Downloaded on June 25,2025 at 10:47:02 UTC from IEEE Xplore.  Restrictions apply. \n\n3 \n \nitself from conventional systems by providing better natural \nlanguage  understanding  and  answer  generation  by  utilizing \nthe enhanced capabilities of Ollama and LLama3.  Real-time \ninteraction solutions are assured by the unique mix of these \ntools. \n \nFig. 2. Sample Dataset Files \nC. Testing Model performance \nThis part shows the procedures carried out to assess the \nchatbot's  correctness  and  performance.  The  chatbot's \nperformance and accuracy were tested using manual question-\nand-answer validation. Initially, we conducted manual testing \nby asking the chatbot various questions related to its context. \nThe bot responded accurately to most queries, showcasing its \ncapabilities and the effectiveness of the prompt design and \nLLM integration. To validate the performance, we conducted \nreal-world  testing  with  10  university  students.  These \nparticipants were asked to pose any five questions related to \nMarwadi University. \nThe  chatbot  demonstrated  exceptional  performance, \naccurately answering all questions posed by 10 participants. \nThis validates its reliability within the intended domain. Table \nI summarizes the results, where \"Tester\" represents the user, \n\"Qs\"  denotes  the  Number  of  Questions,  \"Rs\"  signifies  the \nNumber of Responses, and \"C. Rs\" indicates the Number of \nCorrect Responses. \n \n \nFig. 3. Ollama prompt process Diagram \nTABLE I.  TESTER\n PERFORMANCE SUMMARY \nTester No. Qs No. Rs No. C. Rs \nTester_1 5 5 5 \nTester_2 5 5 5 \nTester_3 5 5 5 \nTester_4 5 5 5 \nTester 1 5 5 5 \nTester 1 5 5 5 \nTester 1 5 5 5 \nTester 1 5 5 5 \nTester 1 5 5 5 \nTester 1 5 5 5 \nTotal \n50 50 50 \n \nD. Front End \nThe  frontend  serves  as  the  user  interface,  providing  an \nintuitive  and  accessible  platform  for  interacting  with  the \nchatbot.  The  interface  includes  key  pages  such  as  Home, \nLogin,  Signup,  Chat,  and  Talk.  The  Home  page  (Fig. 4) \nfeatures  a  menu  bar  with  three  options:  Home,  Login,  and \nSignup,  accompanied  by  the  MU  Bot  logo.  A  welcome \nmessage introduces the user to the chatbot, followed by two \nprimary options (chat and talk). \nAccess to these options requires the user to be logged in. \nUnauthenticated users are redirected to the Login page. The \nLogin page enables users to log in with their username and \npassword, while new users can create accounts via the Signup \npage. The Signup form verifies password confirmation and \nchecks for unique usernames before creating a new account. \n \nAuthorized licensed use limited to: VIT University. Downloaded on June 25,2025 at 10:47:02 UTC from IEEE Xplore.  Restrictions apply. \n\n4 \n \n \nFig. 4. Home Page \nThe  Chat  section  displays  a  history  of  previous \ninteractions  and  provides  a  text  box  for  new  prompts  (As \nshown in Fig. 5). In the Talk section, users can interact using \nvoice  commands  via  a  microphone  icon.  The  system \ntranscribes  the  user’s  speech,  displays  the  transcription  for \nconfirmation, and processes the input. Talk sections include a \n3D bot model at the center of the interface, enhancing user \nengagement. The bot’s responses are displayed on the screen \nand  read  aloud.  Fig. 6 depicts  the  interaction  and response \nusing voice. \nE. BACK END \nThe  backend,  developed  using  Django  and  MySQL, \nhandles user authentication, data processing, and interaction \nmanagement. The database  is  hosted  on  XAMPP, ensuring \nseamless connectivity and data management. In the Signup \nprocess,  the  system  validates  password  confirmation  and \nchecks for unique usernames. If the criteria are met, a new user \nis added to the database, and a success message is displayed. \nThe  Login  process  verifies  the  entered  username  and \npassword  against  the  database,  granting  or  denying access \nbased on the results. Users can log out via a dedicated logout \noption.  Fig.  7  shows  the  User  Database  for  storing user \naccount details. \n \n \nFig. 5. Chat Section \n \n \nFig. 6. Talk Section \nPrompt  processing  for  both  Chat  and  Talk  sections \ninvolves  integrating  the  user  input  with  LangChain and \nLlama3.  For  the  Chat  section,  the  user’s  text  prompt  is \nprocessed by the backend server, combined with LangChain, \nand sent to the Llama3 model for generating a response. The \nresponse is displayed on the user interface and stored in the  \ndatabase. \n \n \nFig. 7. User’s Database \n \nIn the Talk section, the user’s speech is transcribed and \nverified.  The  transcription  undergoes  the  same  processing \nsteps  as  text  input,  ensuring  consistent  results.  The  bot’s \nresponses are both displayed on the interface and read aloud. \nThe system stores all interactions in the database, enabling \nfuture reference and analysis (Fig. 8). \n \nFig. 8. Promte Response \nThis robust backend ensures secure  user  authentication, \nefficient prompt processing, and seamless integration between \nthe chatbot’s various functionalities, delivering a reliable and \nuser-friendly experience. \nIV. CONCLUSION\n AND FUTURE WORK \nTo wrap up, this project showcases a unique method for \ndeveloping  an  AI-powered  chatbot  tailored  to  academic \nenvironments, using technologies like Ollama, LLama3, and \nLangChain.  By  gathering  data  manually,  organizing  it \nproperly, and designing a user-friendly interface, the system \nis  able  to  provide  real-time,  accurate,  and  context-aware \nresponses for both students and parents. The system's software  \nis  structured  to  provide  secure  logins,  make  the  process \nsmoothly changed , and efficient data handling, making the \nchatbot an effective tool for improving communication at the \nuniversity. What sets this project apart is its incorporation of \nmodern technologies, which offer clear benefits compared to \nolder methods. It strikes a balance between manual precision \nand automation, ensuring both flexibility and reliability. By \nsolving  important  challenges  in  conversational  AI, this \nchatbot lays the foundation for future innovations in university \ncommunication systems.  \nThis work makes the response between the user and the \nchatbot and the real user experience more accurate and finds \nthe  way  to  build  the  chatbots  with  enhanced  real-time  and \ndynamic capabilities. By using this way, we are looking to the \nAuthorized licensed use limited to: VIT University. Downloaded on June 25,2025 at 10:47:02 UTC from IEEE Xplore.  Restrictions apply. \n\n5 \n \nfuture  to  make  it  automate  learning  by  itself  based  on \nreinforcement learning, which is the most advanced technique \nin  AI,  and  also,  we  will  try  to  monitor  the  response  and \nmeasure the time for each and every request. \n \nREFERENCES \n[1]   T. T. Nguyen, A. Le, H. Hoang, and T. Nguyen, “Neu-chatbot: Chatbot \nfor admission of national economics university,” Comput. Educ. Artif. \nIntell., vol. 2, p. 100036, 2021.  \n[2]   W.  E.  Villegas-Ch.,  A.  Arias-Navarrete,  and  X.  Palacios-Pacheco, \n“Proposal of an architecture for the integration of a chatbot with artificial \nintelligence  in  a  smart  campus  for  the  improvement of  learning,” \nSustainability, 2020.  \n[3]  H. M. Dinh and T. K. Tran, “Educhat: An ai-based chatbot for university-\nrelated information using a hybrid approach,” Applied Sciences, 2023.  \n[4]   K. C. Sarker, M. M. Rahman, and A. Siam, “Anglo-bangla language-\nbased  ai  chatbot  for  bangladeshi  university  admission  system,”  2023 \nInternational Conference on Communications, Computing and Artificial \nIntelligence (CCCAI), pp. 42–46, 2023.  \n[5]   N. I. M. Rahim, N. A. Iahad, A. F. Yusof, and M. A. Al-Sharafi, “Ai-\nbased  chatbots  adoption  model  for  higher-education institutions:  A \nhybrid  pls-sem-neural  network  modelling  approach,” Sustainability, \n2022.  \n[6]  K. Ramalakshmi, D. J. David, M. Selvarathi, and T. J. Jebaseeli, “Using \nartificial intelligence methods to create a chatbot for university questions \nand answers,” RAiSE-2023, 2023.  \n[7]   S. Neupane, E. Hossain, J. Keith, H. Tripathi, F. Ghiasi, N. A. Golilarz, \nA. Amirlatifi, S. Mittal, and S. Rahimi, “From questions to insightful \nanswers: Building an informed chatbot for university resources,” ArXiv, \nvol. abs/2405.08120, 2024.  \n[8]  R.  R.  Chand  and  N.  Sharma,  “Development  of  bilingual  chatbot  for \nuniversity  related  faqs  using  natural  language  processing  and  deep \nlearning,” in DataCom, 2022.  \n[9] B. R. Ranoliya, N. Raghuwanshi, and S. Singh, “Chatbot for university \nrelated faqs,” 2017 International Conference on Advances in Computing, \nCommunications and Informatics (ICACCI), pp. 1525–1530, 2017.  \n[10] E. I. Setiawan, G. S. Kurniawan, J. Santoso, and Y. S. H. Langgeng, \n“Chatbot  for  university  students  major  determination  with  rasa \nframework,” 2023 27th International Computer Science and Engineering \nConference (ICSEC), pp. 299–303, 2023.  \n \n \nAuthorized licensed use limited to: VIT University. Downloaded on June 25,2025 at 10:47:02 UTC from IEEE Xplore.  Restrictions apply. ","metadata":{"source":"papers/pdf1.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.4","IsAcroFormPresent":false,"IsXFAPresent":false,"Title":"Developing a User-Friendly Conversational AI Assistant for University Using Ollama and LLama3","Subject":"2025 International Conference on Data Science, Agents &amp; Artificial Intelligence (ICDSAAI);2025; ; ;10.1109/ICDSAAI65575.2025.11011878","Creator":"Certified by IEEE PDFExpress at April 25, 2025 00:36:41","Producer":"Neevia Document Converter Pro v7.3.0.184 (http://neevia.com); modified using iText® Core 7.2.4 (AGPL version) ©2000-2022 iText Group NV","CreationDate":"D:20250301154900Z","ModDate":"D:20250524182543-04'00'"},"metadata":{"_metadata":{"dc:format":"application/pdf","dc:publisher":"IEEE","dc:description":"2025 International Conference on Data Science, Agents &amp; Artificial Intelligence (ICDSAAI);2025; ; ;10.1109/ICDSAAI65575.2025.11011878","dc:title":"Developing a User-Friendly Conversational AI Assistant for University Using Ollama and LLama3","dc:subject":"ChatbotPrompt EngineeringOllamaUniversity ChatbotLarge Language Model","dc:creator":"Jayrajsinh GohilHagos L.ShifareMadhu Shukla","prism:publicationname":"2025 International Conference on Data Science, Agents &amp; Artificial Intelligence (ICDSAAI)","prism:startingpage":"1","prism:coverdisplaydate":"28 March 2025","prism:doi":"10.1109/ICDSAAI65575.2025.11011878","prism:endingpage":"5","jav:journal_article_version":"VoR"}},"totalPages":5}}}],["cfbc82cb-3b50-4944-b22a-c99a500fefef",{"pageContent":"Gen AI driven FAQ chatbot using Advanced RAG \nArchitecture for Querying Annual reports \n \n         Mehul K                    Dr. V. R. Kanagavalli                             Ms. Saradha K R \nDepartment of Information Technology               Department of Humanities and Science              Department of Information Technology \n           Sri Sairam Engineering College                            Sri Sairam Engineering College                       Sri Sairam Engineering College \n    Chennai, India                         Chennai, India                  Chennai, India \n       \nmehulkrishieee@gmail.com                       kanagavalli.math@sairam.edu.in        saradha.it@sairam.edu.in  \n \n \n      Gowtham P N           Sachin M P                Surya U \nDepartment of Information Technology          Department of Computer Science and Engineering        Department of Information Technology \n         Sri Sairam Engineering College                (Artificial Intelligence and Machine Learning)             Sri Sairam Engineering College \n      Chennai, India                                                Sri Sairam Engineering College                      Chennai, India \n        gowthamnaren2017@gmail.com         Chennai, India                suryajup17@gmail.com  \n        m.p.sachin265@gmail.com  \n \n \n Godhandaraman R            Girish S                           Naveen R \nDepartment of Information Technology                 Department of Mechanical Engineering             Department of Information Technology \n        Sri Sairam Engineering College           Sri Sairam Engineering College     Sri Sairam Engineering College \n     Chennai, India                       Chennai, India                    Chennai, India \n        \ngodhandaraman313@gmail.com                  girishofficial04@gmail.com            naveen685685@gmail.com  \n \nAbstract—In    the    rapidly    evolving    business    landscape, \nstakeholders  require  timely  and  accurate  access  to  financial  and \noperational  information  from  annual  reports.  However,  the \nextensive and complex nature of these reports makes it difficult to \nefficiently  extract  key  analytical  trends,  financial  performance \nmeasures,  and  comparative  insights.  The  traditional  manual \napproach  to  analyse  these  documents  is  time-consuming,  error \nprone,    and    inefficient.    Stakeholders—including    creditors, \ncustomers,   suppliers,   employees,   government   agencies,   and \nindustry analysts—rely on this data to make informed decisions. \nThe  absence  of  an  automated  mechanism  to  handle  frequent \nqueries regarding financial performance, operational metrics, and \nsustainability   targets   impedes   large-scale   informed   decision \nmaking.  This  paper  presents  a  Gen  AI-driven  solution  that \nleverages   Natural   Language   Processing   (NLP),   LangChain \nFramework   and   Retrieval   Augmented   Generation   (RAG) \nArchitecture  to  efficiently  extract  and  analyze  financial  annual \nreports and its data. The approach involves utilizing PyPDF2 for \ndata extraction, segmenting content using \nRecursiveCharacterTextSplitter,    generating    embeddings    via \nFastEmbedEmbeddings   module,   and   storing   information   in \nQdrant  for  rapid  similarity  search.  The  response  generation  is \npowered by DeepSeek LLM, deployed locally via Ollama, ensuring \nprivacy  and  computational  efficiency.  A  Gradio-based  UI  is \nimplemented  for  an  intuitive  interface.  This  system  enhances \nfinancial  data  accessibility,  fostering  transparency,  compliance, \nand data-driven decision-making. \n \nKeywords—Financial  Report Analysis, AI  Query  System,RAG \nArchitecture,  NLP,  LangChain  Framework,  Qdrant,  Ollama, \nGradio. \nI. INTRODUCTION \nAnnual  financial  reports  contain  critical  information  on  a \ncompany’s  financial  health,  operational  efficiency,  and \nstrategic plans. However, stakeholders often struggle to extract \nprecise insights due to the document’s complexity. Traditional \nsearch  mechanisms  and  manual  data  retrieval  methods  are \ninefficient,  requiring  significant  time  and  effort  to  locate \nrelevant information. \nIn response to this challenge, an AI-driven financial query \nsystem is proposed, that automates the extraction and analysis \nof annual reports. The system utilizes PyPDF2 for structured \ndata  extraction,  an  advanced  chunking  mechanism  for  text \nsegmentation,  and  Qdrant  for  vector-based  retrieval.  The \nsystem also incorporates DeepSeek LLM, hosted locally via \nOllama,  to  process  user  queries. A  Gradio-based  UI  ensures \nseamless user interaction. \n1\n                       2025 International Conference on Computing and Communication Technologies (ICCCT)\n979-8-3315-3757-9/25/$31.00 ©2025 IEEE\n2025 International Conference on Computing and Communication Technologies (ICCCT) | 979-8-3315-3757-9/25/$31.00 ©2025 IEEE | DOI: 10.1109/ICCCT63501.2025.11020025\nAuthorized licensed use limited to: VIT University. Downloaded on June 25,2025 at 10:48:16 UTC from IEEE Xplore.  Restrictions apply. \n\nII. LITERATURE SURVEY \nThe  authors  in  [1]  tackle  the  shortcomings  of  current \nmultimodal Retrieval-Augmented Generation (RAG) systems, \nwhich  have  difficulty  effectively  grasping  and  using  the \nconnections between text and images. Standard RAG models \nare great at retrieving and adding to text data, but they struggle \nto  produce  consistent  replies  when  dealing  with  multimodal \ndocuments that have intricate text-image connections. To get \naround these issues, the authors suggest a better multimodal \nRAG structure that boosts retrieval and generation by explicitly \nfactoring in image-text relationships. They assess how well this \nmethod works by comparing it against four question-answering \ndatasets—Short-form QA, Long-form QA, MCQ-type QA, and \nTrue-False  QA—showing  significant  advancements  over \ncurrent methods, with additional insights gained from testing \nwith large multimodal models like OpenAI’s and Gemini’s. \nThe  authors  in  [2],  tackle  the  challenge  of  extracting \ninformation from unstructured documents, such as URLs and \nPDFs.  These  types  of  documents  are  difficult  to  search \nefficiently because of their complex and unorganized nature. \nTraditional  systems  for  text  analysis  often  struggle  with \ninteractivity,  flexibility,  and  integrating  data,  which  reduces \ntheir effectiveness for these kinds of tasks. To address this, the \nauthors  suggest  a  new  approach  that  uses  LangChain’s \nadvanced natural language processing, combined  with Dash, \nGoogle  Generative  AI,  and  FAISS.  This  method  aims  to \nenhance  the  efficiency  of  extraction  and  analysis. The \neffectiveness  of  this  system  is  demonstrated  through \nexperiments, showing considerable gains in both accuracy and \nspeed. This  is  further  enhanced  by  features  like  annotation, \nquery  storage,  bookmarking,  text-to-speech,  and  translation \ninto ten different languages. \nThe  authors  of  [3]  tackle  the  growing  problem  of  how \nawkward and slow it can be to work with PDF files. It’s a hassle \nlots  of  people  are  running  into,  especially  since  digital \ndocuments are becoming the norm, but old-school PDF viewers \njust aren’t cutting it when it comes to actually using them. Basic \nPDF readers can’t really pull out important info, give a quick \nsummary, or let easily search or ask questions about the text, \nleaving users with fewer options than they should have. To fix \nthis, the authors are looking into something called LangChain, \nwhich is a language model built to make grabbing information, \nsummarizing  documents,  searching  through  them,  getting \nanswers to questions, and even translating them way smoother. \nLangChain  does  this  by  combining  really  good  natural \nlanguage understanding with a deep dive into the documents \nthemselves. The authors check out how well LangChain works \nby examining its inner workings and testing it out in real-life \nsituations, showing that it can really boost how much people \ncan get done, how easy it is to access information, and how well \nteams can work together. \nThe  research  described  in  [4]  addresses  the  challenge  of \ndealing  with  information  overload  in  large  documents,  a \nproblem where traditional methods fail to adequately capture \nthe  essential  points  for  users.  Existing  tools  generally  can’t \nhandle summarization and question-answering tasks efficiently \nwhen  it  comes  to  large-scale  documents,  often  leading  to \nreduced productivity. To combat this issue, the authors propose \na new framework for creating personalized chatbots that utilize \nLarge  Language  Models  (LLMs).  They  integrate  OpenAI, \nLangChain, and Streamlit to enhance the document processing \ncapabilities  of  these  chatbots.  The  effectiveness  of  this \nframework is assessed by examining its design and real-world \nuse  cases.  A  detailed  walkthrough  showcases  how  the \nframework  greatly  improves  the  speed  and  accuracy  of \ninformation retrieval, ultimately enhancing user productivity. \nThe authors of [5] delve into the shortcomings of early AI \nchatbots,  noting  their  lack  of  versatility  and  responsiveness \nwhen compared to human cognitive abilities. This limitation \nconfined their practical applications. Traditional models were \ndesigned for specific, narrow tasks and struggled with diverse \ncontent  creation  and  the  effective  processing  of  multimodal \ndata. To address this, the authors introduce modern generative \nAI chatbots, equipped with Large Language Models (LLMs) \nfor textual tasks and Large Multimodal Models (LMMs) for \nhandling various forms of data. These advanced chatbots can \ngenerate a wide range of content, including text, images, audio, \nvideo,  code,  virtual  worlds,  datasets,  and  web  content.  The \nstudy  meticulously  categorizes  their  capabilities  into  eight \ndistinct groups, showcasing their adaptability and efficiency in \nreal-world scenarios. \nThe  authors  of  [6]  introduce  an AI  system  for  document \nmanagement  with  LangChain  and  Pinecone.  The  article \ndescribes  how  documents  are  divided  into  small  pieces, \ntransformed into numbers, and saved for rapid searching. When \na user queries, the system retrieves the most relevant data and \nprovides an answer through AI. This assists in rapid finding, \nsummarizing,  and  comprehending  documents.  The  research \npoints to its application in fields such as law, education, and \nbusiness to make information handling manageable on a large \nscale. \nThe  authors  of  [7]  introduce  an AI  system  for  document \nmanagement  with  LangChain  and  Pinecone.  The  article \ndescribes  how  documents  are  divided  into  small  pieces, \ntransformed into numbers, and saved for rapid searching. When \na user queries, the system retrieves the most relevant data and \nprovides an answer through AI. This assists in rapid finding, \nsummarizing,  and  comprehending  documents.  The  research \npoints to its application in fields such as law, education, and \nbusiness to make information handling manageable on a large \nscale. \n2\nAuthorized licensed use limited to: VIT University. Downloaded on June 25,2025 at 10:48:16 UTC from IEEE Xplore.  Restrictions apply. \n\nIII. METHODOLOGY \nThe advanced tools and techniques such as Natural Language \nProcessing  (NLP),  LangChain  Framework  and  Retrieval \nAugmented Generation (RAG) Architecture is being employed \nfor  building  Gen-AI  Driven  FAQ  Chatbot,  user-friendly-\ninterface  to  improve  access  and  decision-making  tasks  for \nstakeholder. It has five phases: data extraction using PyPDF2; \ntext-processing chunking; embedding-generation and reranking \nof chunks; retrieval and query processing with the intervention \nof DeepSeek LLM; finally, and it is deployed using Gradio UI. \nA. Data Extraction Using PyPDF2 \nThe  methodology’s  first  phase  emphasizes  standard \napproaches  to  extract  textual  content  from  these  financial \nreports. These finance assessments are readily available in PDF \nformat. In doing so, PyPDF2-a standard Python library is used \nto parse and read PDF files. The system will use PyPDF2 to \nsystematically  extract  raw  text  from  these  documents  while \nmaintaining the sequential order of content while being able to \nefficiently  organise  the  multi-page  reports.  Annual  and \nQuarterly  Financial  reports  usually  contain  narrative  text, \nnumerical data, and publishing structure elements like tables \nthat  dictate  a  robust  extraction  rationale.  The  extraction \nprocedure  commences  with  loading  the  PDF  into  memory. \nSubsequently, the pages are looped through to fetch the text \nmaterial. A lightweight instruction set drives the process, telling \nPyPDF2 to pull precise and pertinent content like nonaudited \nfinancial  statements,  management  reports,  SEC-required \ndisclosure statements, and tabular data while ignoring irrelevant \nor redundant content such as headers, footers, or repetitively \nredundant boilerplate text. To validate the extraction procedure, \na preliminary check is done on the output to ensure that certain \ncritical  sections,  such  as  financial  summaries  or  legal \ndisclosures,  are  accurately  captured.  By  applying  precision \nprinciples in PyPDF2 extraction and enhancing the quality of \nsubsequent  data  processing,  the  aim  of  providing  reliable \ninsights to system stakeholders-such as creditors, analysts, and \nregulators-is then facilitated. \n \nB. Text Processing and Chunking \nThe  next  phase  is  one  in  which  the  raw  text  has  been \nextracted;  it  now  requires  some  form  of  processing and \nsegmentation to suit the analysis. Most often, these financial \nreports  include  very  long,  unstructured  narratives that  are \ninterspersed with structured elements; hence, a very systematic \nmethod for text handling is called for. This phase includes two \nimportant  steps:  loading  the  extracted  text  into  a structured \nformat; and segmenting it into small manageable pieces. Upon \nextraction,  the  document  is  first  rendered  into  Markdown \nformat  in  the  process  of  parsing.  Subsequently,  the  text  is \nloaded    into    a    document    object    using    the \nUnstructuredMarkdownLoader module. This loader is crucial \nin  preserving  the  integrity  of  formatting  elements typical  of \nfinancial reports, such as detail tables presenting revenue or \nexpenses, succinct bullet points summarizing key metrics, and \nother  structure  types  that  encode  truly  complex  financial \ninformation. In this way, it helps in keeping the structure intact \nand  ensures  that  the  meaning  and  context  of  the  data  are \npreserved. It thereby avoids tasks such as errant table entries, or \nbroken lists that may actually happen for the raw text. \nOnce  the  loading  process  is  completed,  the  structured \ndocument would undergo segmentation using the \n \nFig. 3.1. System Architecture \nRecursiveCharacterTextSplitter module. This splits the text into \na number of smaller coherent pieces, establishing boundaries \nbased on both the character limits and logical breaks such as \nparagraph breaks or section heads. This process aims to create \nchunks that are not only stand-alone in that they contain enough \ncontext and information, but they are also reasonably few in \nsize—usually not exceeding a pre-established character length \nduring processing such as 1000 characters, which will make \nindexing and searching for relevant information much easier \nlater. The recursive character of the splitter makes sure that, in \ncase of long sections, the splitting is done iteratively to maintain \nreadibility  and  avoid  unnaturally  breaking  words  apart  into \nobscure fragments. \nC. Embedding Generation and Reranking of Chunks \nThe  system  converts  segmented  texts  into  numerical \nembeddings to facilitate effective financial data retrieval. The \n(POS) part-of-speech tagging of the text is performed utilizing \nthe library of NLTK’s Averaged Perceptron Tagger. This helps \nstructure the text and process it in a more compliant manner. \nThe  level  of  semantic  understanding  is  improved,  and  the \nquality of the resulting embeddings is thus enhanced aboard. \nThe  text  chunks  are  then  processed  by  fast  embeddings, \ngenerating high-dimensional vector representations that capture \ncontextual  relationships  within  financial  reports. The \nembeddings allow financial terminology to be contextualized, \nso that related terms like ”revenue” and ”profit” are located \nclose in the vector space. This stage is critical for executing \n3\nAuthorized licensed use limited to: VIT University. Downloaded on June 25,2025 at 10:48:16 UTC from IEEE Xplore.  Restrictions apply. \n\naccurate  similarity  searches  for  improving  the  quality  of \nretrieval. \nThe  embeddings  generated  are  stored  in  ChromaDB,  an \nadvanced  vector  database  optimized  for  rapid  similarity \nsearches  and  structured  indexing.  ChromaDB  organizes  and \nrelates every vector with relevant metadata-such as section title \nand page number-for efficient retrieval across large financial \ndocuments.  Its  indexing  methods  allow  for  low-latency \nsearches,  even  among  huge  reports.  For  further  precision, \nFlashrankRerank,  the  sophisticated  reranking  model which \nessentially rearranges results based on the relative importance \nof  context,  is  used.  FlashrankRerank  therefore  ranks  the \nretrieved chunks from query intent such that the most relevant \nfinancial  insights  occupy  the  peak  position.  This  helps \neliminate  noise  and  subsequently  improve  extracted data \nprecision. Integration of POS tagging, embedding generation, \nefficient  vector storage, and  intelligent reranking determines \nthe  method  of  optimum  retrieval  of  financial  data, thus \nproviding  stakeholders  with  accurate,  fast,  and  contextually \naware  insights.  This  ensures  easy  extraction  of  valuable \ninformation by financial professionals, investors, and analysts \nalike in support of informed decisionmaking that streamlines \nfinancial analysis workflows. \nD. Retrieval and Query Processing Using DeepSeek LLM \nThe fourth phase integrates retrieval and response generation \nto effectively handle stakeholder queries. The process combines \nQdrant’s  vector-based  retrieval  with  the  natural  language \nunderstanding capability of DeepSeek LLM deployed in a local \ncontext via Ollama for better privacy and efficiency. \nWhen a user sends a query (for example,”What are the key \nfinancial    highlights?”),    it    passes    through    the \nFastEmbedEmbeddings  module  and  gets  turned  into  an \nembedding that is consistent with the vectors stored within the \nreport.  The  embedding  is  then  used  to  perform  a  similarity \nsearch in Qdrant to identify the top-k text chunks that are most \nrelevant, either based on cosine similarity or Euclidean distance \nmetrics. The retrieved chunks are basically the portions of the \nfinancial report that are reasonable candidates for doing what is \nbeing  asked,  such  as  revenue  summaries  or  management \ncommentaries.  The  extracted  chunks  go  off  to  DeepSeek,  a \nnatural language-generation-oriented large language model, for \nfurther elaboration. DeepSeek, through Ollama, processes the \nchunks alongside the user query and generates a cohesive and \naccurately  contextualized  answer.  A  user-defined  function \nformats the output so that it can actually be read with some ease. \nThe  function  extracts  the  main  content  from  the  LLM’s \nresponse dictionary and makes sure it reads well by using the \ntextwrap library to wrap the text at 100 characters. This function \ntakes care of empty lines, with proper spacing while not just \nbreaking  the  words  unnecessarily,  thus  keeping  long \nsummarizes of complex  financial data clearly readable. This \nretrieval approach and processing of the user query ensure that \nthe  stakeholders  get  precise,  comprehensible  responses  from \nthe  content  of  the  report.  DeepSeek  being  deployed locally \nthrough Ollama enhances computational efficiency and privacy \nof data, while the integration to retrieve quickly through Qdrant \nsupports timely decision-making and  meets the transparency \nand usability objective of the system. \nE. User Interface and Deployment \nThe last phase will work on delivering the system in a user-\nfriendly  fashion  via  its  UI  and  local  deployment  through \nOllama. The UI is based on Gradio and is interactive and simple \nto work with so that the stakeholders can input financial queries \nand  obtain  structured  responses.  Gradio  offers  an  extremely \nlight  framework  for  real-time  interactions;  users  can  upload \nfinancial reports, pose targeted inquiries, and obtain \n                 Fig. 3.2. Class Diagram \n \n \nwell-structured insights right in their web browsers-an essential \nfeature  that  ensures  even  nontechnical  users  can  effectively \nnavigate and extract relevant financial information. The system \nis deployed locally through Ollama rather than being hosted on \nthe cloud, with enhanced privacy, security, and computational \nefficiency.  Since  Ollama  enables  on-device  execution  of  the \nDeepSeek LLM, there is no need for external servers, reducing \nreliance on third-party cloud infrastructure. This means that the \nsystem  can  run  the  model  locally  for  very  low-latency \nperformance  while  guaranteeing  full  control  over  sensitive \nfinancial data. Furthermore, by deploying the system locally, \noperational costs will be reduced, providing a feasible scenario \nfor organizations with strict data compliance requirements. \n \n     This way of UI and deployment works as a bridge between \nadvanced AI-driven analytics and the stakeholder needs. The \ninfusion  of  user-friendly  transactions  through  Gradio  and \nsecure,  on-device  Ollama  deployment  ensures  rigorous, \ntransparent,  and  data-driven  decisions  for  financial  analysts, \nindustry professionals, and regulatory bodies alike. \nIV. RESULTS AND DISCUSSION \nExperiments  demonstrate  that  the AI-driven  query  system \nsignificantly improves the efficiency and accuracy of financial \n4\nAuthorized licensed use limited to: VIT University. Downloaded on June 25,2025 at 10:48:16 UTC from IEEE Xplore.  Restrictions apply. \n\ndata retrieval. The below figure 4.1 shows the User Interface of \nthe chat bot.   \n \nFig. 4.1. Output \n \nCompared  to  traditional  search  mechanisms,  the  system \ndelivers near-instant responses with higher relevance, reducing \nmanual effort. The integration of DeepSeek LLM with Qdrant \nensures   context-aware   and  precise   financial   insights. \nFurthermore,  hosting  via  Ollama  and  Gradio  enhances  user \nexperience and accessibility. \n \n \nFig 4.2. Performance of the System \n \n      Here,  Figure  4.2  analyses  the  retrieval  effectiveness  and \nperformance  of  the  system.  The  first  chart  displays  the \nrelevance scores of retrieved responses for various questions, \nindicating  accuracy  with  scores  nearing  0.9.  Similarly,  the \nsecond graph displays the distribution of response time ranging \nfrom 1.2 seconds to 1.7 seconds , while maintaining an overall \nhigh level of accuracy (>0.85). The third graph evaluates how \nchunk  size  affects  accuracy  and  suggests  a  maximum \nachievable  value  for  accuracy  at  about  0.90,  then  falls  into \nminimal decline. \n \nV. CONCLUSION \nThe financial report analysis platform powered by Gen-AI \nhas  been  successfully  implemented,  with  financial  and \noperational  information  made  more  accessible  and  usable. \nThrough NLP and Retreival Augmented Generation (RAG) the \nplatform streamlines the extraction, segmentation, and retrieval \nof key financial information, enabling finance teams to spend \nmore  time  on  analysis  rather  than  data  work.  PyPDF2  was \nemployed for parsing documents, the \nRecursiveCharacterTextSplitter module for text segmentation \ninto  sections,  and  FastEmbedEmbeddings  with  Qdrant for \nstorage and retrieval efficiency. DeepSeek LLM, deployed on \nOllama, delivers precise, context-specific answers to enhance \nfinancial insights. The user interface, developed using Gradio, \nprovides an interactive means for investors, financial analysts, \nauditors, and regulators to view financial information. \nThe system enhances financial information access, facilitates \ntransparency and compliance, and enables companies to make \ninformed  data-driven  decisions.  It  automates  financial \ndocuments  processing,  extracts  meaningful  insights,  and \nenables stakeholders to identify trends, risks, and opportunities \nfaster. The platform is now live, aiding in financial analysis and \nstrategic planning. \n \n \n \nVI. REFERENCE \n[1] Joshi, P., Gupta, A., Kumar, P., & Sisodia, M. (2024, June). \nRobust multi model rag pipeline for documents containing text, \ntable  &  images.  In  2024  3rd  International  Conference  on \nApplied Artificial Intelligence and Computing (ICAAIC) (pp. \n993-999). IEEE. \n[2] Priya, K., Kamath, A., Chandan, K. M., Praveen, C., Omkar, \nS. N., & Aaditya,  S. J. (2024, November). Enhancing Q&A \nSystems  with  Multilingual  Text  Conversion  and  Speech \nIntegration:  Harnessing  the  Power  of  LangChain  and Large \nLanguage  Models.  In  2024  8th  International  Conference  on \nComputational  System  and  Information  Technology  for \nSustainable Solutions (CSITSS) (pp. 1-6). IEEE. \n[3]  Kotiyal,  A.,  Gujjar,  P.,  Prasad,  G.,  Devadas,  R.  M., \nHiremani, V., & Tangade, P. (2024, July). Chat With PDF Using \nLangChain Model. In 2024 Second International Conference \non Advances in Information Technology (ICAIT) (Vol. 1, pp. \n1-4). IEEE. \n[4] Pokhrel, S., Ganesan, S., Akther, T., & Karunarathne, L. \n(2024).  Building  Customized  Chatbots  for  Document \nSummarization and Question Answering using Large Language \nModels  using  a  Framework  with  OpenAI,  Lang  chain,  and \nStreamlit.  Journal  of  Information  Technology  and  Digital \nWorld, 6(1), 70-86. \n[5] Naik, D., Naik, I., & Naik, N. (2024). The AI Engine of \nCreation: Exploring the Capabilities of AI Chatbots based on \n5\nAuthorized licensed use limited to: VIT University. Downloaded on June 25,2025 at 10:48:16 UTC from IEEE Xplore.  Restrictions apply. \n\nGenerative AI, Large Language Models and Large Multimodal \nModels. Authorea Preprints. \n[6] Pesaru, A., Gill, T. S., & Tangella, A. R. (2023). AI assistant \nfor document management Using Lang Chain and Pinecone. \nInternational   Research   Journal   of   Modernization   in \nEngineering Technology and Science, 5(6), 3980-3983. \n[7]  Pandya,  K.,  &  Holia,  M.  (2023). Automating  Customer \nService using LangChain: Building custom open-source GPT \nChatbot for organizations. arXiv preprint arXiv:2310.05421. \n \n6\nAuthorized licensed use limited to: VIT University. Downloaded on June 25,2025 at 10:48:16 UTC from IEEE Xplore.  Restrictions apply. ","metadata":{"source":"papers/pdf2.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.4","IsAcroFormPresent":false,"IsXFAPresent":false,"Title":"Gen AI Driven FAQ Chatbot Using Advanced RAG Architecture for Querying Annual Reports","Subject":"2025 International Conference on Computing and Communication Technologies (ICCCT);2025; ; ;10.1109/ICCCT63501.2025.11020025","Producer":"PyPDF2; modified using iTextSharp 5.4.1 ©2000-2012 1T3XT BVBA (AGPL-version); modified using iText® Core 7.2.4 (AGPL version) ©2000-2022 iText Group NV","CreationDate":"D:20250531112400+05'30'","ModDate":"D:20250604042625-04'00'"},"metadata":{"_metadata":{"dc:format":"application/pdf","dc:publisher":"IEEE","dc:description":"2025 International Conference on Computing and Communication Technologies (ICCCT);2025; ; ;10.1109/ICCCT63501.2025.11020025","dc:title":"Gen AI Driven FAQ Chatbot Using Advanced RAG Architecture for Querying Annual Reports","dc:subject":"Financial Report AnalysisAI Query SystemRAG ArchitectureNLPLangChain FrameworkQdrantOllamaGradio","dc:creator":"Mehul KV. R. KanagavalliSaradha K RGowtham P NSachin M PSurya UGodhandaraman RGirish SNaveen R","prism:publicationname":"2025 International Conference on Computing and Communication Technologies (ICCCT)","prism:startingpage":"1","prism:coverdisplaydate":"16 April 2025","prism:doi":"10.1109/ICCCT63501.2025.11020025","prism:endingpage":"6","jav:journal_article_version":"VoR"}},"totalPages":6}}}],["01b6d069-c1f1-479c-a0cc-9af30ffa2787",{"pageContent":"Emotional Intelligence in Chatbots: A Study on\nEnhancing User Experience with Llama3 and\nOllama\nSalini Suresh\nBangalore, India\npnsalinisuresh@gmail.com\nRachna Rathore\nDept.of Mathematics\nJiwaji University\nGwalior, India\nrachnarathore1109@gmail.com\nhttps://orcid.org/0000-0001-8753-888X\nShailendra Thapliyal\nDept. of Management\nUttaranchal University\nDehradun, India\nshailendra@uumail.in\nAjith Sundaram\nDept. of Business\nAmrita Vishwa Vidyapeetham\nKochi, India\najithsundaram@gmail.com\nSaloni Bansal\nDept. of Computer Eng. & Applications\nGLA University\nMathura, India\nsaloni.bansal@gla.ac.in\nKabir Gaba\nDept. of CSE (AIML), CSE-APEX\nChandigarh University\nChandigarh, India\nkabirgaba002@gmail.com\nAbstract—The    field    of    emotional    support    chatbots    has\nbecome   a   significant   part   of   the   tools   designed   to   enhance\nmental well-being through human-like conversations. This paper\nintroduces an innovative approach that prioritizes empathy and\ncontext  continuity.  The  proposed  solution,  named  ”SOLARA”\nutilizes  the  Llama3.2:3b  model  within  the  Ollama  framework.\nBy  incorporating  sentiment  analysis  powered  by  fuzzy  logic,\nSOLARA  delivers  context-aware,  personalized,  and  empathetic\nresponses.  The  Llama3.2:3b  model  enhances  SOLARA’s  ability\nto   understand   complex   language   and   retain   memory   more\neffectively. With Ollama enabling offline functionality, SOLARA\nensures   user   privacy   and   reliability.   Compared   to   existing\nsolutions, this approach demonstrates improvements in emotional\naccuracy,  response  quality,  and  conversational  coherence.  The\nsolution highlights the potential of NLP in addressing emotional\nconcerns while balancing performance and user privacy, paving\nthe way for further exploration in this field.\nIndex Terms—Ollama, Llama3.2\nI.  INTRODUCTION\nBackground & Importance of NLP in Emotional Support:\nThis   We   are   aware   of   NLP’s   emergence   as   a   major\ntool   for   chatbots’   development,   specifically   for   the   ones\nbuilt  for  emotional  support.  Accessibility,  empathy,  and  a\ncommunication which is not judgmental, all of this is provided\nby these systems to help users overcome mental and emotional\nchallenges  [1].  A  continuous  and  personalized  experience\ngiven  by  these  support  chatbots  is  something  which  even  a\nhuman  cannot  match  to,  if  we  consider  it  in  the  terms  of\navailability  and  comfort  for  users.  Complex  emotions  cannot\nbe  understood  by  traditionally  built,  rule-based  systems,  as\n979-8-3315-2169-1/25/$31.00 ©2025 IEEE\nsuch systems are just made to follow a structured approach but\nemotions do not work in that way. Such systems mostly fail in\nunderstanding user’s emotion or generating a response that can\nmatch a human intellect [2]. NLP has however achieved a great\nimprovement  and  advancements  as  well  which  enhances  its\nability in handling such inputs. This feature is a must to have\nfeature  for  an  emotional  support  chatbot,  as  these  chatbots\nneed  to  analyze  even  a  subtle  change  in  the  user’s  emotion\nwhile maintaining the understanding of context.\nThe Need for Advanced Models: Llama3.2:3b :\nMore   parameters,   more   data,   more   understanding   and\ngeneralization  on  a  much  better  level  is  what  an  advanced\nmodel like Llama3.2 offers. Earlier models were trained well\nand  had  a  great  efficiency  in  handling  complex  inputs,  but\nwhy  to  settle  in  less  when  you  have  a  better  option?  These\nadvanced  models  have  a  lot  to  offer  along  with  removing\nthe shortcomings of the earlier models. Sustaining coherence\nand providing a sensitive response are the things with utmost\nimportance  when  it  is  about  emotional  support.  And  these\nare  the  key  features  of  Llama3.2,  its  architecture  makes  it\ncapable  of  achieving  all  of  this,  making  it  convenient  and\nmore  preferrable  option.  By  leveraging  improved  memory\nretention and natural language understanding, this model offers\na deeper, more human-like engagement, making it a key tool\nin enhancing the user’s emotional experience with the chatbot.\nRole of Ollama Framework for Offline Availability:\nMaking   emotional   support   available   consistently,   even\noffline  is  the  key  idea  at  the  core  of  the  work  discussed\nin  this  paper.  And  that  is  where  Ollama  framework  comes\ninto  action  and  makes  this  task  possible,  by  allowing  the\n2025 IEEE International Conference on Interdisciplinary Approaches in Technology and Management for Social Innovation (IATMSI) | 979-8-3315-2169-1/25/$31.00 ©2025 IEEE | DOI: 10.1109/IATMSI64286.2025.10984885\nAuthorized licensed use limited to: VIT University. Downloaded on June 25,2025 at 10:47:34 UTC from IEEE Xplore.  Restrictions apply. \n\nLlama3.2 model to run effectively offline. Which is essential\nin maintaining the privacy, making it more reliable, which is\nreally  a  significant  variable  to  keep  in  mind  while  dealing\nwith  sensitive  emotional  disclosures  [3].  All  of  this  makes\nsure  that  users  can  take  benefit  of  such  systems  even  in  an\nenvironment without connectivity. And that too without giving\naway the performance or accuracy metrics, as the features of\nLlama3.2 will be made offline with Ollama framework. Trust\nis a variable that is given lesser weight many a time, but not in\nthis proposal, the offline feature makes it more trustable than\nany other model available in this stream.\nVision for the Proposal:\nA   chatbot   that   is   highly   sensitive   with   its   language,\nunderstands emotions on a high level and that can work both\noffline  and  online  and  that  too  efficiently.  That  is  all  this\napproach  aims  to  achieve,  with  the  help  of  Llama3.2:3b’s\nfineness and accuracy in handling complex data like emotions,\nalong  with  Ollama  framework  which  makes  it  work  offline\nwith the same effectiveness as in online mode [4]. Integrating\nall this with fuzzy logic refines the working of chatbot offering\na better response. With the help of this study, it is aimed to set\nhigh standards in the field of emotional support and self-help\nchatbots in the terms of empathetic, intellectual responses and\na better understanding of emotional cues and making sure that\nprivacy  and  security  is  there  too  on  a  high  level.  A  solution\nthat users can trust and they can feel extremely real.\nII.  RELATED WORK\nCabezas  et  al.  (2024)  integrated  a  LLaMA-based  chatbot\nwith  augmented  retrieval  generation  to  assist  students.  The\nproposed   system   showed   promise   as   a   complementary\neducational  tool  for  high  school  and  college  learners  [5].\nKaushik (2024) investigated dynamic data scaling techniques\nfor   streaming   machine   learning,   providing   insights   into\noptimizing chatbot frameworks for dynamic environments and\nlarge-scale  operations  [6].  Bilquise  et  al.  (2022)  conducted\na   systematic   review   on   emotionally   intelligent   chatbots,\noutlining   key   methodologies   for   incorporating   sentiment\nanalysis  and  empathetic  responses  into  conversational  agents\n[7].   Shrivastava   and   Rathore   (2024)   analyzed   a   single\nserver   Markovian   queuing   model   with   specific   features\nsuch  as  vacation  interruptions  and  customer  reneging.  Their\nfindings   contribute   to   optimizing   resource   allocation   in\nchatbot  server  frameworks  [8].  Sasan  (2024)  introduced  a\nmedical chatbot based on LLaMA 2, showcasing its potential\nin   patient   consultation   and   medical   information   delivery\nwhile   addressing   accuracy   and   contextual   challenges   [9].\nRathore  et  al.  (2024)  investigated  the  integration  of  fog  and\nedge  computing  into  intelligent  transportation  systems  for\nnavigation. Their research provided a foundation for enhancing\nchatbot  functionalities  in  transportation  assistance  [10].  Li\nand  Klinger  (2024)  introduced  iPrOp,  a  human-in-the-loop\ninteractive prompt optimization framework for large language\nmodels. The study focused on improving model performance\nand  adaptability  through  iterative  optimization  techniques,\nhighlighting its applications in diverse domains [11].\nYigci  et  al.  (2024)  explored  the  use  of  large  language\nmodel-based  chatbots  in  higher  education,  emphasizing  their\npotential  to  enhance  personalized  learning  experiences  while\naddressing the challenges of scalability and engagement [12].\nRathore et al. (2024) conducted a study on consumer sentiment\nanalysis  using  advanced  machine  learning  techniques.  Their\nfindings offered insights into understanding consumer behavior\nand   preferences   for   business   applications   [13].   Ilieva   et\nal.  (2023)  examined  the  effects  of  generative  chatbots  in\nhigher education, highlighting their impact on student learning\noutcomes and the overall educational experience, particularly\nin  interactive  and  collaborative  learning  settings  [14].  Kooli\n(2023) critically analyzed the ethical implications of chatbots\nin  education  and  research.  The  study  proposed  solutions  to\nmitigate  biases  and  ethical  concerns  while  ensuring  fair  and\nresponsible  AI  deployment  [15].  Rathore  (2023)  assessed\nthe   role   of   AI   in   recruitment   and   selection   processes,\ndiscussing   its   efficiency   in   automating   tasks,   improving\ndecision-making, and reducing hiring biases in organizational\nsettings [16]. Rane (2023) explored chatbot-enhanced teaching\nand   learning,   focusing   on   implementation   strategies   and\nchallenges.   The   study   highlighted   the   role   of   ChatGPT\nin   improving   interactivity   and   engagement   in   educational\nenvironments  [17].  Thamilselvan  et  al.  (2024)  designed  a\nLLaMA   2-powered   chatbot   for   enhanced   college   website\nsupport.  Their  approach  demonstrated  improvements  in  user\nsatisfaction and information retrieval for institutional purposes\n[18].  Rathore  et  al.  (2024)  proposed  a  smart  ecosystem  for\nskin cancer detection, integrating AI for accurate diagnostics.\nThe  study  underlined  the  potential  of  chatbots  in  assisting\nhealthcare  services  with  rapid  and  accessible  consultations\n[19].\nIII.  METHODOLOGY\nOllama Framework: Overview and Offline Functionality-\nMaking   emotional   support   available   consistently,   even\noffline is the key idea at the core of the work discussed in this\npaper. And that is where Ollama framework comes into action\nand makes this task possible, by allowing the Llama3.2 model\nto run effectively offline. Which is essential in maintaining the\nprivacy, making it more reliable, which is really a significant\nvariable to keep in mind while dealing with sensitive emotional\ndisclosures.\nAll  of  this  makes  sure  that  users  can  take  benefit  of  such\nsystems even in an environment without connectivity. And that\ntoo without giving away the performance or accuracy metrics,\nas the features of Llama3.2 will be made offline with Ollama\nframework [20]. Trust is a variable that is given lesser weight\nmany a time, but not in this proposal, the offline feature makes\nit more trustable than any other model available in this stream.\nL1ama3.2 : 3b Model Architecture-\nWhen  GPT-2  was  introduced,  it  was  seen  as  a  significant\nachievement  as  it  could  generate  coherent  text.  But  when\nwe  look  at  the  advance  models  today,  it  looks  too  be  the\nbeginning. Being able to generate a coherent text, that makes\nsense,  that  too  in  real-time  and  then  taking  care  of  social\nAuthorized licensed use limited to: VIT University. Downloaded on June 25,2025 at 10:47:34 UTC from IEEE Xplore.  Restrictions apply. \n\nand  religious  beliefs  into  account  and  not  harming  any  of\nthe beliefs, then being intelligent enough to handle emotional\ninputs,  all  of  this  was  still  like  a  dream.  But  with  the  pace\nall  of  this  has  happened  shows  we  are  leading  to  something\ngetting true soon that seems to be unreal today.\nComprehending  language  on  a  better  level,  and  retaining\nmemory  for  a  longer  period  was  still  needed  to  be  achieved,\nthat  Llama3.2:3b  have  now  achieved  on  a  satisfactory  level\n[21].  Multi-turn  conversations  along  with  keeping  track  of\nemotions,   making   it   more   human-like   with   the   help   of\noptimization  in  its  architecture.  Being  able  to  analyze  subtle\nand  delicate,  very  fine  cues  in  input  texts  with  the  help  of  a\nhuge number of parameters. Llama3.2:3b proves to be a better\nversion than all of its predecessors.\nKey features of the model include:\n•Enhanced Memory Retention.\n•Improved Emotional Understanding.\n•Resource Efficiency.\nFuzzy Logic in Sentiment Analysis for Emotional Recognition:\nIntegrating  fuzzy  logic  with  these  simple  models  can  be\nproven  as  a  significant  step  towards  a  realistic  mimicking  of\nhuman  mind  in  understanding  and  responding  to  emotional\nqueries. Rather than having structured and fixed rigid options,\nwe  look  forward  to  explore  a  more  flexible  and  unexplored\npath  in  the  field  of  sentiment  analysis  and  responding  in\naccordance  to  that.  For  example,  a  user  may  express  queries\nthat are partially ”anxious” and partially ”sad,” and fuzzy logic\nhelps  the  system  generate  responses  that  acknowledge  this\nuncertainty and complexity.\nIt  has  been  done  previously  by  many  of  the  available\nsolutions but there was a narrow scope explored and focused,\nfor example focusing on binary or ternary states of mind. But\nhere we have focused on having a much deeper understanding\nof  emotions  by  having  a  complex  pool  of  target  values  [22].\nThis makes it the best available option for applications in this\nfield, in which users often express mixed or unclear feelings.\nThe  fuzzy  logic  system  integrated  with  Solara  examines\nuser  inputs  on  the  basis  of  a  pre-planned  emotional  scaling,\nmapping  the  level  of  emotions  and  their  combinations.  For\ninstance, a user statement like ”I’m feeling a little anxious but\nalso better than previous” might be calculated as 60% anxious\nand  40%  relieved.  On  the  basis  of  this  analysis,  Solara  can\nrespond that takes care of both emotions, offering support that\nfeels more personalized and empathetic.\nContext Preservation and Response Generation in Solara:\nThis   paper   proposes   an   approach   that   may   act   as   a\ngame-changer, the empathy is given the maximum importance\nhere along with continuity of the context. Maintaining context\nis   one   of   the   major   challenges   in   an   emotional   helping\nchatbots.  A  user  may  start  referring  to  something  mentioned\nearlier in the past, in case our bot could not retain the data of\nthe  incident,  it  will  lead  to  a  spoiled  conversation.  Llama3.2\nis  the  solution,  that  we  offer  in  this  approach,  as  it  can  help\nSolara to retain context across multiple conversation turns.\nContinuous updating of memory state for keeping a record\nof  necessary  details  from  conversations  is  the  key  technique\nused to manage context preservation. Model references to this\nmemory state every time it has to respond to some query, to\nmaintain the feeling of personalization.\nFlow Diagram ((or the architecture of Solara using Llama3.2:3b)-\nThe  architecture  of  Solara,  powered  by  the  Llama3.2:3b\nmodel, is structured to handle user input in several steps:\n•Input Processing: User inputs are first processed through\nan NLP pipeline, where tokenization and initial sentiment\nanalysis take place.\n•Fuzzy Logic Sentiment Analysis: The fuzzy logic system\nevaluates the emotional content of the input, determining\nthe degree to which various emotions are present.\n•Contextual  Memory  Update:  The  context  memory  is\nupdated with the user’s latest input, ensuring that previous\nconversation details are retained.\nFig. 1.   Solara Architecture Flow Diagram\nIV.  EXPERIMENTAL SETUP\nDataset and Preprocessing for Sentiment Analysis:\nThe   dataset   proposed   to   be   used   is   an   amalgamated\nversion of publicly available datasets and custom conversations\nmanually tailored for maintaining sensitiveness. Emotion Lines\nand  Daily  Dialog  are  the  few  of  the  popularly  used  datasets\nalso used in this approach.\nPreprocessing:\n1)  Tokenization\n2)  Lowercasing and Lemmatization\n3)  Stopword Removal\n4)  Emotion Labeling\nTools and Platforms (Llama3.2:3b and Ollama Framework)-\nThe  experimental  setup  leverages  the  Llama3.2:3b  model\nfor  natural  language  understanding  and  response  generation,\nwhile the Ollama framework ensures offline functionality.\nLlama3.2:3b -\nComprehending  language  on  a  better  level,  and  retaining\nmemory  for  a  longer  period  was  still  needed  to  be  achieved,\nthat  Llama3.2:3b  have  now  achieved  on  a  satisfactory  level.\nMulti-turn conversations along with keeping track of emotions,\nmaking it more human-like with the help of optimization in its\nAuthorized licensed use limited to: VIT University. Downloaded on June 25,2025 at 10:47:34 UTC from IEEE Xplore.  Restrictions apply. \n\narchitecture.  Being  able  to  analyze  subtle  and  delicate,  very\nfine  cues  in  input  texts  with  the  help  of  a  huge  number  of\nparameters. Llama3.2:3b proves to be a better version than all\nof its predecessors.\nOllama Framework:\nMaking   emotional   support   available   consistently,   even\noffline is the key idea at the core of the work discussed in this\npaper. And that is where Ollama framework comes into action\nand makes this task possible, by allowing the Llama3.2 model\nto run effectively offline. Which is essential in maintaining the\nprivacy, making it more reliable, which is really a significant\nvariable to keep in mind while dealing with sensitive emotional\ndisclosures\nSoftware Stack:\n•Python 3.9\n•Pytorch\n•FuzzyWuzzy\nEvaluation Metrics (Response Quality, Latency, Emotional Accuracy):\nTo  assess  the  effectiveness  of  Solara,  several  evaluation\nmetrics were employed:\n•Response  Quality:  This  was  calculated  with  the  help  of\nreviews and feedbacks taken from users.\n•Latency: How quickly the responses are generated.\n•Emotional  Accuracy:  This  metric  evaluates  how  nicely\nthe chatbot understands a user’s emotions and inputs.\nQualitative Metrics:\n•Empathy Score\n•Continuity\nTesting Environment (Online vs. Offline):\nTo  evaluate  the  performance  of  Solara  in  both  connected\nand  offline  settings,  two  primary  testing  environments  were\nestablished:\nOnline Testing:\nA remote server and an online interface were used to host\nSolana  and  take  queries  from  the  users.  How  it  will  perform\nwhile  having  access  to  high  computational  power  could  be\ntested easily in this environment.\nOffline Testing:\nIn this mode a normal consumer system was used to evaluate\nworking of the approach discussed in this paper. Latency and\nmemory usage were evaluated in this mode to check whether\nthere is any degradation in performance in this mode. And, if\nthere is any, is it significant enough to suggest a major change\nor refinement of the architecture.\nV.  RESULTS\nModel Performance of Llama3.2:3b Compared to Llama2-\nThe Llama3.2-\n3b model has shown major and significant betterments over\nits  predecessor,  Llama2,  specifically  in  handling  emotional\nsupport  conversations.  Key  areas  of  performance  that  were\nevaluated  include  context  retention,  response  coherence,  and\nemotional sensitivity.\nContext Retention:\nThere  was  a  lesser  context  loss  observed  as  compared  to\nLllama2  and  there  was  a  better  memory  retention  generally.\nLlama3.2   could   go   up   to   92%   of   accuracy   in   retaining\ncontext,  while  Llama2  could  manage  to  have  only  78%.\nWhich  suggests  Llama3.2  is  better  in  terms  of  maintaining\nand handling longer conversations.\nFig. 2.   Context Retention Comparison\nResponse Coherence:\nTo evaluate this metric, user feedbacks were used. To avoid\nany  misjudgment,  a  team  of  neutral  human  evaluators  was\nset  up  for  evaluating  this  metric.  On  a  scale  of  5  both  were\nevaluated and even here Llama3.2 outperformed with a score\nof 4.6, while Llama2 got only 3.9.\nEmotional Sensitivity:\nLlama3.2  was  observed  to  be  more  empathetic,  backed\nby  the  diverse  emotional  conversation-based  datasets  used\nto  train  it.  Even  this  metric  suggested  the  same  thing  that\nLlama3.2 is much better than Llama2, as it could 87% times\naccurately capture emotional needs and could tailor a response\nin accordance to that.\nFig. 3.  Accuracy Comparison of Traditional Sentiment vs Solara (Llama 3.2)\nSentiment  Analysis  &  Fuzzy  Logic  Impact  on  Emotional\nAwareness:\nThe integration of fuzzy logic in Solara’s sentiment analysis\nsignificantly improved the chatbot’s emotional awareness. This\napproach  allowed  the  system  to  interpret  user  emotions  on\na  spectrum  rather  than  assigning  them  to  rigid  categories,\nresulting in more nuanced and accurate emotional responses.\nAuthorized licensed use limited to: VIT University. Downloaded on June 25,2025 at 10:47:34 UTC from IEEE Xplore.  Restrictions apply. \n\nFig. 4.   Intent Category Distribution\nTABLE I\nTRADITIONAL SENTIMENT ANALYSIS VS SOLARA\nMetricTraditional\nSentiment\nAnalysis  System\nSolara\nSentiment\nRecognition\nAccuracy\n67%82%\nMulti-Emotion\nResponses\n-Exists\nEmotional  Depth\nin Responses\n4.1/5.04.8/5.0\nVI.  CONCLUSION\nPaper   presents   a   significant   advancement   in   emotional\nsupport  chatbots  by  introducing  SOLARA,  which  integrates\nthe Llama3.2:3b model and the Ollama framework to enhance\nuser   interaction   through   improved   emotional   intelligence.\nThe  methodology  employed  includes  the  use  of  advanced\nNLP  techniques  for  context  preservation  and  fuzzy  logic  for\nnuanced  sentiment  analysis,  allowing  for  more  accurate  and\nhuman-like interactions. The experimental setup demonstrated\nSOLARA’s   superiority   over   previous   models   in   terms   of\nemotional accuracy, context retention, and response coherence.\nResults  from  both  online  and  offline  testing  environments\naffirmed the effectiveness of the SOLARA system in providing\nempathetic and contextually aware responses, highlighting its\npotential  to  operate  independently  of  network  connectivity,\nthus ensuring privacy and constant availability. This innovative\napproach sets a new benchmark for chatbots in mental health\nsupport,  combining  technological  sophistication  with  deep\nemotional  understanding,  thereby  enhancing  the  overall  user\nexperience.\nVII.  DISCUSSION AND ANALYSIS\nLlama3.2:3b’s   Role   in   Improving   Emotional   Response\nGeneration-\nMore   parameters,   more   data,   more   understanding   and\ngeneralization  on  a  much  better  level  is  what  an  advanced\nmodel like Llama3.2 offers. Earlier models were trained well\nand  had  a  great  efficiency  in  handling  complex  inputs,  but\nwhy  to  settle  in  less  when  you  have  a  better  option?  These\nadvanced models have a lot to offer along with removing the\nshortcomings of the earlier models.\nSustaining  coherence  and  providing  a  sensitive  response\nare   the   things   with   utmost   importance   when   it   is   about\nemotional support. And these are the key features of Llama3.2,\nits  architecture  makes  it  capable  of  achieving  all  of  this,\nmaking   it   convenient   and   more   preferrable   option.   By\nleveraging  improved  memory  retention  and  natural  language\nunderstanding,  this  model  offers  a  deeper,  more  human-like\nengagement,  making  it  a  key  tool  in  enhancing  the  user’s\nemotional experience with the chatbot.\nAdvantages of Fuzzy Logic in Classifying User Emotions:\nIntegrating  fuzzy  logic  with  these  simple  models  can  be\nproven  as  a  significant  step  towards  a  realistic  mimicking  of\nhuman  mind  in  understanding  and  responding  to  emotional\nqueries. Rather than having structured and fixed rigid options,\nwe  look  forward  to  explore  a  more  flexible  and  unexplored\npath  in  the  field  of  sentiment  analysis  and  responding  in\naccordance  to  that.  For  example,  a  user  may  express  queries\nthat are partially ”anxious” and partially ”sad,” and fuzzy logic\nhelps  the  system  generate  responses  that  acknowledge  this\nuncertainty and complexity.\nIt  has  been  done  previously  by  many  of  the  available\nsolutions but there was a narrow scope explored and focused,\nfor example focusing on binary or ternary states of mind. But\nhere we have focused on having a much deeper understanding\nof emotions by having a complex pool of target values. This\nmakes it the best available option for applications in this field,\nin which users often express mixed or unclear feelings.\nThe advantages of using\n•fuzzy logic include\n•Improved Emotional Accuracy\n•Personalized Interactions\nOverall,  fuzzy  logic  has  proven  to  be  a  valuable  tool  for\nimproving the chatbot’s emotional intelligence, allowing it to\nhandle  a  wider  range  of  emotional  expressions  and  deliver\nmore personalized responses.\nInsights  from  Offline  Availability  for  User  Privacy  and\nReliability:\nMaking   emotional   support   available   consistently,   even\noffline is the key idea at the core of the work discussed in this\npaper. And that is where Ollama framework comes into action\nand makes this task possible, by allowing the Llama3.2 model\nto run effectively offline. Which is essential in maintaining the\nprivacy, making it more reliable, which is really a significant\nvariable to keep in mind while dealing with sensitive emotional\ndisclosures.\nAll  of  this  makes  sure  that  users  can  take  benefit  of  such\nsystems even in an environment without connectivity. And that\ntoo without giving away the performance or accuracy metrics,\nas the features of Llama3.2 will be made offline with Ollama\nframework. Trust is a variable that is given lesser weight many\na  time,  but  not  in  this  proposal,  the  offline  feature  makes  it\nmore trustable than any other model available in this stream.\nAuthorized licensed use limited to: VIT University. Downloaded on June 25,2025 at 10:47:34 UTC from IEEE Xplore.  Restrictions apply. \n\nOffline availability, therefore, not only enhances privacy but\nalso  ensures  that  Solara  can  provide  reliable  and  continuous\nemotional   support,   independent   of   external   connectivity\nfactors.\nVIII.  LIMITATIONS ANDCHALLENGES\nDespite   the   mentioned   achievements   and   betterments\nachieved   by   Solara,   there   are   still   some   limitations   and\nchallenges, as mentioned below:\nIncreased Latency in Offline Mode:\nOllama  framework  is  especially  used  in  this  approach  to\nmake Solana available offline but with that functionality comes\nan  issue  in  terms  of  response  time.  In  low-end  devices  it\nwas  worse  than  those  with  higher  resources  available.  The\n1.8-second   average   response   time   in   offline   mode,   while\nacceptable,  was  higher  than  the  1.2  seconds  achieved  in  the\nonline mode. This slight latency could affect user experience\nin cases where real-time responsiveness is crucial.\nHardware Limitations:\nTo  run  the  Llama3.2:3b  model  on  a  local  device  needs\nsignificant memory and processing power, which may lead to\nlimited accessibility of the chatbot for users with devices with\nlow-end  resources.  Enough  optimizations  have  been  made  in\nthis  approach  to  reduce  the  memory  need  but  still  a  1.6  GB\nof  memory  usage  is  high  for  certain  devices  with  low  level\nresources, potentially which may hinder the usability for some\nusers.\nComplexity of Emotion Interpretation:\nDespite  the  fact  that  fuzzy  logic  has  been  implemented\nin  this  approach,  but  emotional  complexity  still  remains  a\nhurdle.  There  were  cases  where  it  struggled  to  accurately\nweigh overlapping emotions, particularly when the inputs were\nvague or ambiguous. For instance, phrases like ”I don’t know\nhow I feel” posed challenges for the system, which sometimes\nled to inaccurate emotional analysis.\nAddressing   these   challenges   in   future   iterations   of   the\nchatbot  will  be  essential  in  improving  Solara’s  scalability,\nresponse time, and emotional accuracy.\nREFERENCES\n[1]  I.  A.  Pap  and  S.  Oniga,  “eHealth  Assistant  AI  Chatbot  Using  a  Large\nLanguage  Model  to  Provide  Personalized  Answers  through  Secure\nDecentralized  Communication,”Sensors,  vol.  24,  no.  18.  MDPI  AG,\np. 6140, Sep. 23, 2024.\n[2]  S. Tiwari, S. Kumar, S. Tyagi and M. Poonia, ”Crop Recommendation\nusing   Machine   Learning   and   Plant   Disease   Identification   using\nCNN  and  Transfer-Learning  Approach,”  2022IEEE  Conference  on\nInterdisciplinary Approaches in Technology and Management for Social\nInnovation (IATMSI), Gwalior, India, 2022.\n[3]  G.  Caldarini,  S.  Jaf,  and  K.  McGarry,  “A  Literature  Survey  of  Recent\nAdvances  in  Chatbots,”Information,  vol.  13,  no.  1.  MDPI  AG,  p.  41,\nJan. 15, 2022.\n[4]  A.  Gupta,  S.  Kumar  and  P.  M.  Pattanaik,  ”A  Novel  HISMO  Solution\nto  Coverage  Hole  Mitigation  in  6G-IoT,”  2022IEEE  Conference  on\nInterdisciplinary Approaches in Technology and Management for Social\nInnovation (IATMSI), Gwalior, India, 2022, pp. 1-5.\n[5]  D. Cabezas, R. Fonseca-Delgado, I. Reyes-Chac\n ́\non, P. Vizcaino-Imaca\n ̃\nna,\nand   M.   Morocho-Cayamcela,   “Integrating   a   LLaMa-based   Chatbot\nwith Augmented Retrieval Generation as a Complementary Educational\nTool  for  High  School  and  College  Students,”Proceedings  of  the  19th\nInternational  Conference  on  Software  Technologies.  SCITEPRESS  -\nScience and Technology Publications, pp. 395–402, 2024.\n[6]  Kaushik,  P.  (2024).  Dynamic  Data  Scaling  Techniques  for  Streaming\nMachine   Learning.International   Journal   for   Global   Academic   &\nScientific Research, 3(1), 1–12.\n[7]  G.   Bilquise,   S.   Ibrahim,   and   K.   Shaalan,   “Emotionally   Intelligent\nChatbots:   A   Systematic   Literature   Review,”Human   Behavior   and\nEmerging Technologies, vol. 2022. Wiley, pp. 1–23, Sep. 26, 2022.\n[8]  Shrivastava,   R.   K.,   &   Rathore,   R.   (2024).   Analysis   of   Single\nServer   Markovian   Queueing   Model   with   Differentiated   Working\nVacation,  Vacation  Interruption,  Soft  Failure,  Reneging  of  Customers.\nInternational Journal for Global Academic & Scientific Research, 3(3),\n01–13.\n[9]  A. P. S. Sasan, “A Research Paper of a Medical Chatbot using Llama 2,”\nInternational Journal for Research in Applied Science and Engineering\nTechnology, vol. 12, no. 4.International Journal for Research in Applied\nScience and Engineering Technology (IJRASET), pp. 859–865, Apr. 30,\n2024.\n[10]  R. Rathore, P. Kaushik, S. S. Sikarwar, H. Joshi, A. K. Mishra and Y.\nHudda, ”Intelligent Transportation Systems Make Use of Fog and Edge\nComputing  for  Navigation,”  2024  IEEEInternational  Conference  on\nInterdisciplinary Approaches in Technology and Management for Social\nInnovation (IATMSI), Gwalior, India, 2024, pp. 1-6.\n[11]  Li, J., & Klinger, R. (2024). iPrOp: Interactive Prompt Optimization for\nLarge Language Models with a Human in the Loop (Version 1).arXiv.\nhttps://doi.org/10.48550/ARXIV.2412.12644\n[12]  D. Yigci, M. Eryilmaz, A. K. Yetisen, S. Tasoglu, and A. Ozcan, “Large\nLanguage   Model-Based   Chatbots   in   Higher   Education,”Advanced\nIntelligent Systems. Wiley, Aug. 11, 2024.\n[13]  S. P. S. Rathore, J. Patole, G. Tilak, R. Lenka, J. C. Lopez and Priyanka,\n”Consumer  Sentiment  Analysis,”  2023International  Conference  on\nSmart Devices (ICSD), Dehradun, India, 2024, pp. 1-5.\n[14]  G. Ilieva, T. Yankova, S. Klisarova-Belcheva, A. Dimitrov, M. Bratkov,\nand D. Angelov, “Effects of Generative Chatbots in Higher Education,”\nInformation, vol. 14, no. 9. MDPI AG, p. 492, Sep. 07, 2023.\n[15]  C. Kooli, “Chatbots in Education and Research: A Critical Examination\nof  Ethical  Implications  and  Solutions,”Sustainability,  vol.  15,  no.  7.\nMDPI AG, p. 5614, Mar. 23, 2023.\n[16]  Pratap  Singh  Rathore,  S.  (2023).  The  Impact  of  AI  on  Recruitment\nand  Selection  Processes:  Analysing  the  role  of  AI  in  automating  and\nenhancing  recruitment  and  selection  procedures.International  Journal\nfor Global Academic & Scientific Research, 2(2), 51–63.\n[17]  N.  Rane,  “Chatbot-Enhanced  Teaching  and  Learning:  Implementation\nStrategies, Challenges, and the rRole of ChatGPT in Education,”SSRN\nElectronic Journal. Elsevier BV, 2023.\n[18]  R.   Thamilselvan,   P.   Natesan,   A.   Manimaran,   S.   E.   Naveenkumar,\nJ.    K.    Shanthosh,    and    S.    Vigneshwaran,    “Designing    A    Llama\n2-Powered   Chatbot   for   Enhanced   College   Website   Support,”   2024\n15thInternational   Conference   on   Computing   Communication   and\nNetworking Technologies (ICCCNT). IEEE, pp. 1–6, Jun. 24, 2024.\n[19]  R. Rathore, H. Yennapusa, S. Kumar, M. Mahawar, S. Miglani and G.\nSharma, ”Cutting-Edge Skin Cancer Detection in a Smart Ecosystem,”\n2023International  Conference  on  Smart  Devices  (ICSD),  Dehradun,\nIndia, 2024, pp. 1-5.\n[20]  B.  Keum,  J.  Sun,  W.  Lee,  S.  Park,  and  H.  Kim,  “Persona-Identified\nChatbot   through   Small-Scale   Modeling   and   Data   Transformation,”\nElectronics, vol. 13, no. 8. MDPI AG, p. 1409, Apr. 09, 2024.\n[21]  K.  Ramalakshmi,  D.  J.  David,  M.  Selvarathi,  and  T.  J.  Jebaseeli,\n“Using Artificial Intelligence Methods to Create a Chatbot for University\nQuestions and Answers,”RAiSE-2023. MDPI, p. 16, Dec. 11, 2023.\n[22]  J.  Kaushik  and  S.  Kumar,  ”Design  and  Performance  Benchmarking  of\n8T SRAM Cell using Dynamic Feedback Control,” 2023 IEEEIndustrial\nElectronics  and  Applications  Conference  (IEACon),  Penang,  Malaysia,\n2023, pp. 81-85.\nAuthorized licensed use limited to: VIT University. Downloaded on June 25,2025 at 10:47:34 UTC from IEEE Xplore.  Restrictions apply. ","metadata":{"source":"papers/pdf3.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.5","IsAcroFormPresent":false,"IsXFAPresent":false,"Title":"Emotional Intelligence in Chatbots: A Study on Enhancing User Experience with Llama3 and Ollama","Subject":"2025 IEEE International Conference on Interdisciplinary Approaches in Technology and Management for Social Innovation (IATMSI);2025;3; ;10.1109/IATMSI64286.2025.10984885","Creator":"TeX","Producer":"pdfTeX-1.40.26; modified using iText® Core 7.2.4 (AGPL version) ©2000-2022 iText Group NV","CreationDate":"D:20250208193349Z","ModDate":"D:20250506172600-04'00'"},"metadata":{"_metadata":{"dc:format":"application/pdf","dc:publisher":"IEEE","dc:description":"2025 IEEE International Conference on Interdisciplinary Approaches in Technology and Management for Social Innovation (IATMSI);2025;3; ;10.1109/IATMSI64286.2025.10984885","dc:title":"Emotional Intelligence in Chatbots: A Study on Enhancing User Experience with Llama3 and Ollama","dc:subject":"OllamaLlama3.2","dc:creator":"Salini SureshRachna RathoreShailendra ThapliyalAjith SundaramSaloni BansalKabir Gaba","prism:publicationname":"2025 IEEE International Conference on Interdisciplinary Approaches in Technology and Management for Social Innovation (IATMSI)","prism:startingpage":"1","prism:coverdisplaydate":"6 March 2025","prism:doi":"10.1109/IATMSI64286.2025.10984885","prism:volume":"3","prism:endingpage":"6","jav:journal_article_version":"VoR"}},"totalPages":6}}}]],{"0":"0803c827-69a0-4130-8073-d98ce60473b6","1":"cfbc82cb-3b50-4944-b22a-c99a500fefef","2":"01b6d069-c1f1-479c-a0cc-9af30ffa2787"}]